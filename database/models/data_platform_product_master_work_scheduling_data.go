// Code generated by SQLBoiler 4.13.0 (https://github.com/volatiletech/sqlboiler). DO NOT EDIT.
// This file is meant to be re-generated in place and/or deleted at any time.

package models

import (
	"context"
	"database/sql"
	"fmt"
	"reflect"
	"strconv"
	"strings"
	"sync"
	"time"

	"github.com/friendsofgo/errors"
	"github.com/volatiletech/null/v8"
	"github.com/volatiletech/sqlboiler/v4/boil"
	"github.com/volatiletech/sqlboiler/v4/queries"
	"github.com/volatiletech/sqlboiler/v4/queries/qm"
	"github.com/volatiletech/sqlboiler/v4/queries/qmhelper"
	"github.com/volatiletech/strmangle"
)

// DataPlatformProductMasterWorkSchedulingDatum is an object representing the database table.
type DataPlatformProductMasterWorkSchedulingDatum struct {
	Product                       string       `boil:"Product" json:"Product" toml:"Product" yaml:"Product"`
	BusinessPartner               int          `boil:"BusinessPartner" json:"BusinessPartner" toml:"BusinessPartner" yaml:"BusinessPartner"`
	Plant                         string       `boil:"Plant" json:"Plant" toml:"Plant" yaml:"Plant"`
	ProductionInvtryManagedLoc    null.String  `boil:"ProductionInvtryManagedLoc" json:"ProductionInvtryManagedLoc,omitempty" toml:"ProductionInvtryManagedLoc" yaml:"ProductionInvtryManagedLoc,omitempty"`
	ProductProcessingTime         null.Int     `boil:"ProductProcessingTime" json:"ProductProcessingTime,omitempty" toml:"ProductProcessingTime" yaml:"ProductProcessingTime,omitempty"`
	ProductionSupervisor          null.String  `boil:"ProductionSupervisor" json:"ProductionSupervisor,omitempty" toml:"ProductionSupervisor" yaml:"ProductionSupervisor,omitempty"`
	ProductProductionQuantityUnit null.String  `boil:"ProductProductionQuantityUnit" json:"ProductProductionQuantityUnit,omitempty" toml:"ProductProductionQuantityUnit" yaml:"ProductProductionQuantityUnit,omitempty"`
	ProdnOrderIsBatchRequired     null.Bool    `boil:"ProdnOrderIsBatchRequired" json:"ProdnOrderIsBatchRequired,omitempty" toml:"ProdnOrderIsBatchRequired" yaml:"ProdnOrderIsBatchRequired,omitempty"`
	PDTCompIsMarkedForBackflush   null.Bool    `boil:"PDTCompIsMarkedForBackflush" json:"PDTCompIsMarkedForBackflush,omitempty" toml:"PDTCompIsMarkedForBackflush" yaml:"PDTCompIsMarkedForBackflush,omitempty"`
	ProductionSchedulingProfile   null.String  `boil:"ProductionSchedulingProfile" json:"ProductionSchedulingProfile,omitempty" toml:"ProductionSchedulingProfile" yaml:"ProductionSchedulingProfile,omitempty"`
	MinimumLotSizeQuantity        null.Float32 `boil:"MinimumLotSizeQuantity" json:"MinimumLotSizeQuantity,omitempty" toml:"MinimumLotSizeQuantity" yaml:"MinimumLotSizeQuantity,omitempty"`
	StandardLotSizeQuantity       null.Float32 `boil:"StandardLotSizeQuantity" json:"StandardLotSizeQuantity,omitempty" toml:"StandardLotSizeQuantity" yaml:"StandardLotSizeQuantity,omitempty"`
	LotSizeRoundingQuantity       null.Float32 `boil:"LotSizeRoundingQuantity" json:"LotSizeRoundingQuantity,omitempty" toml:"LotSizeRoundingQuantity" yaml:"LotSizeRoundingQuantity,omitempty"`
	MaximumLotSizeQuantity        null.Float32 `boil:"MaximumLotSizeQuantity" json:"MaximumLotSizeQuantity,omitempty" toml:"MaximumLotSizeQuantity" yaml:"MaximumLotSizeQuantity,omitempty"`
	LotSizeIsFixed                null.Bool    `boil:"LotSizeIsFixed" json:"LotSizeIsFixed,omitempty" toml:"LotSizeIsFixed" yaml:"LotSizeIsFixed,omitempty"`
	IsMarkedForDeletion           null.Bool    `boil:"IsMarkedForDeletion" json:"IsMarkedForDeletion,omitempty" toml:"IsMarkedForDeletion" yaml:"IsMarkedForDeletion,omitempty"`

	R *dataPlatformProductMasterWorkSchedulingDatumR `boil:"-" json:"-" toml:"-" yaml:"-"`
	L dataPlatformProductMasterWorkSchedulingDatumL  `boil:"-" json:"-" toml:"-" yaml:"-"`
}

var DataPlatformProductMasterWorkSchedulingDatumColumns = struct {
	Product                       string
	BusinessPartner               string
	Plant                         string
	ProductionInvtryManagedLoc    string
	ProductProcessingTime         string
	ProductionSupervisor          string
	ProductProductionQuantityUnit string
	ProdnOrderIsBatchRequired     string
	PDTCompIsMarkedForBackflush   string
	ProductionSchedulingProfile   string
	MinimumLotSizeQuantity        string
	StandardLotSizeQuantity       string
	LotSizeRoundingQuantity       string
	MaximumLotSizeQuantity        string
	LotSizeIsFixed                string
	IsMarkedForDeletion           string
}{
	Product:                       "Product",
	BusinessPartner:               "BusinessPartner",
	Plant:                         "Plant",
	ProductionInvtryManagedLoc:    "ProductionInvtryManagedLoc",
	ProductProcessingTime:         "ProductProcessingTime",
	ProductionSupervisor:          "ProductionSupervisor",
	ProductProductionQuantityUnit: "ProductProductionQuantityUnit",
	ProdnOrderIsBatchRequired:     "ProdnOrderIsBatchRequired",
	PDTCompIsMarkedForBackflush:   "PDTCompIsMarkedForBackflush",
	ProductionSchedulingProfile:   "ProductionSchedulingProfile",
	MinimumLotSizeQuantity:        "MinimumLotSizeQuantity",
	StandardLotSizeQuantity:       "StandardLotSizeQuantity",
	LotSizeRoundingQuantity:       "LotSizeRoundingQuantity",
	MaximumLotSizeQuantity:        "MaximumLotSizeQuantity",
	LotSizeIsFixed:                "LotSizeIsFixed",
	IsMarkedForDeletion:           "IsMarkedForDeletion",
}

var DataPlatformProductMasterWorkSchedulingDatumTableColumns = struct {
	Product                       string
	BusinessPartner               string
	Plant                         string
	ProductionInvtryManagedLoc    string
	ProductProcessingTime         string
	ProductionSupervisor          string
	ProductProductionQuantityUnit string
	ProdnOrderIsBatchRequired     string
	PDTCompIsMarkedForBackflush   string
	ProductionSchedulingProfile   string
	MinimumLotSizeQuantity        string
	StandardLotSizeQuantity       string
	LotSizeRoundingQuantity       string
	MaximumLotSizeQuantity        string
	LotSizeIsFixed                string
	IsMarkedForDeletion           string
}{
	Product:                       "data_platform_product_master_work_scheduling_data.Product",
	BusinessPartner:               "data_platform_product_master_work_scheduling_data.BusinessPartner",
	Plant:                         "data_platform_product_master_work_scheduling_data.Plant",
	ProductionInvtryManagedLoc:    "data_platform_product_master_work_scheduling_data.ProductionInvtryManagedLoc",
	ProductProcessingTime:         "data_platform_product_master_work_scheduling_data.ProductProcessingTime",
	ProductionSupervisor:          "data_platform_product_master_work_scheduling_data.ProductionSupervisor",
	ProductProductionQuantityUnit: "data_platform_product_master_work_scheduling_data.ProductProductionQuantityUnit",
	ProdnOrderIsBatchRequired:     "data_platform_product_master_work_scheduling_data.ProdnOrderIsBatchRequired",
	PDTCompIsMarkedForBackflush:   "data_platform_product_master_work_scheduling_data.PDTCompIsMarkedForBackflush",
	ProductionSchedulingProfile:   "data_platform_product_master_work_scheduling_data.ProductionSchedulingProfile",
	MinimumLotSizeQuantity:        "data_platform_product_master_work_scheduling_data.MinimumLotSizeQuantity",
	StandardLotSizeQuantity:       "data_platform_product_master_work_scheduling_data.StandardLotSizeQuantity",
	LotSizeRoundingQuantity:       "data_platform_product_master_work_scheduling_data.LotSizeRoundingQuantity",
	MaximumLotSizeQuantity:        "data_platform_product_master_work_scheduling_data.MaximumLotSizeQuantity",
	LotSizeIsFixed:                "data_platform_product_master_work_scheduling_data.LotSizeIsFixed",
	IsMarkedForDeletion:           "data_platform_product_master_work_scheduling_data.IsMarkedForDeletion",
}

// Generated where

var DataPlatformProductMasterWorkSchedulingDatumWhere = struct {
	Product                       whereHelperstring
	BusinessPartner               whereHelperint
	Plant                         whereHelperstring
	ProductionInvtryManagedLoc    whereHelpernull_String
	ProductProcessingTime         whereHelpernull_Int
	ProductionSupervisor          whereHelpernull_String
	ProductProductionQuantityUnit whereHelpernull_String
	ProdnOrderIsBatchRequired     whereHelpernull_Bool
	PDTCompIsMarkedForBackflush   whereHelpernull_Bool
	ProductionSchedulingProfile   whereHelpernull_String
	MinimumLotSizeQuantity        whereHelpernull_Float32
	StandardLotSizeQuantity       whereHelpernull_Float32
	LotSizeRoundingQuantity       whereHelpernull_Float32
	MaximumLotSizeQuantity        whereHelpernull_Float32
	LotSizeIsFixed                whereHelpernull_Bool
	IsMarkedForDeletion           whereHelpernull_Bool
}{
	Product:                       whereHelperstring{field: "`data_platform_product_master_work_scheduling_data`.`Product`"},
	BusinessPartner:               whereHelperint{field: "`data_platform_product_master_work_scheduling_data`.`BusinessPartner`"},
	Plant:                         whereHelperstring{field: "`data_platform_product_master_work_scheduling_data`.`Plant`"},
	ProductionInvtryManagedLoc:    whereHelpernull_String{field: "`data_platform_product_master_work_scheduling_data`.`ProductionInvtryManagedLoc`"},
	ProductProcessingTime:         whereHelpernull_Int{field: "`data_platform_product_master_work_scheduling_data`.`ProductProcessingTime`"},
	ProductionSupervisor:          whereHelpernull_String{field: "`data_platform_product_master_work_scheduling_data`.`ProductionSupervisor`"},
	ProductProductionQuantityUnit: whereHelpernull_String{field: "`data_platform_product_master_work_scheduling_data`.`ProductProductionQuantityUnit`"},
	ProdnOrderIsBatchRequired:     whereHelpernull_Bool{field: "`data_platform_product_master_work_scheduling_data`.`ProdnOrderIsBatchRequired`"},
	PDTCompIsMarkedForBackflush:   whereHelpernull_Bool{field: "`data_platform_product_master_work_scheduling_data`.`PDTCompIsMarkedForBackflush`"},
	ProductionSchedulingProfile:   whereHelpernull_String{field: "`data_platform_product_master_work_scheduling_data`.`ProductionSchedulingProfile`"},
	MinimumLotSizeQuantity:        whereHelpernull_Float32{field: "`data_platform_product_master_work_scheduling_data`.`MinimumLotSizeQuantity`"},
	StandardLotSizeQuantity:       whereHelpernull_Float32{field: "`data_platform_product_master_work_scheduling_data`.`StandardLotSizeQuantity`"},
	LotSizeRoundingQuantity:       whereHelpernull_Float32{field: "`data_platform_product_master_work_scheduling_data`.`LotSizeRoundingQuantity`"},
	MaximumLotSizeQuantity:        whereHelpernull_Float32{field: "`data_platform_product_master_work_scheduling_data`.`MaximumLotSizeQuantity`"},
	LotSizeIsFixed:                whereHelpernull_Bool{field: "`data_platform_product_master_work_scheduling_data`.`LotSizeIsFixed`"},
	IsMarkedForDeletion:           whereHelpernull_Bool{field: "`data_platform_product_master_work_scheduling_data`.`IsMarkedForDeletion`"},
}

// DataPlatformProductMasterWorkSchedulingDatumRels is where relationship names are stored.
var DataPlatformProductMasterWorkSchedulingDatumRels = struct {
}{}

// dataPlatformProductMasterWorkSchedulingDatumR is where relationships are stored.
type dataPlatformProductMasterWorkSchedulingDatumR struct {
}

// NewStruct creates a new relationship struct
func (*dataPlatformProductMasterWorkSchedulingDatumR) NewStruct() *dataPlatformProductMasterWorkSchedulingDatumR {
	return &dataPlatformProductMasterWorkSchedulingDatumR{}
}

// dataPlatformProductMasterWorkSchedulingDatumL is where Load methods for each relationship are stored.
type dataPlatformProductMasterWorkSchedulingDatumL struct{}

var (
	dataPlatformProductMasterWorkSchedulingDatumAllColumns            = []string{"Product", "BusinessPartner", "Plant", "ProductionInvtryManagedLoc", "ProductProcessingTime", "ProductionSupervisor", "ProductProductionQuantityUnit", "ProdnOrderIsBatchRequired", "PDTCompIsMarkedForBackflush", "ProductionSchedulingProfile", "MinimumLotSizeQuantity", "StandardLotSizeQuantity", "LotSizeRoundingQuantity", "MaximumLotSizeQuantity", "LotSizeIsFixed", "IsMarkedForDeletion"}
	dataPlatformProductMasterWorkSchedulingDatumColumnsWithoutDefault = []string{"Product", "BusinessPartner", "Plant", "ProductionInvtryManagedLoc", "ProductProcessingTime", "ProductionSupervisor", "ProductProductionQuantityUnit", "ProdnOrderIsBatchRequired", "PDTCompIsMarkedForBackflush", "ProductionSchedulingProfile", "MinimumLotSizeQuantity", "StandardLotSizeQuantity", "LotSizeRoundingQuantity", "MaximumLotSizeQuantity", "LotSizeIsFixed", "IsMarkedForDeletion"}
	dataPlatformProductMasterWorkSchedulingDatumColumnsWithDefault    = []string{}
	dataPlatformProductMasterWorkSchedulingDatumPrimaryKeyColumns     = []string{"Product", "BusinessPartner", "Plant"}
	dataPlatformProductMasterWorkSchedulingDatumGeneratedColumns      = []string{}
)

type (
	// DataPlatformProductMasterWorkSchedulingDatumSlice is an alias for a slice of pointers to DataPlatformProductMasterWorkSchedulingDatum.
	// This should almost always be used instead of []DataPlatformProductMasterWorkSchedulingDatum.
	DataPlatformProductMasterWorkSchedulingDatumSlice []*DataPlatformProductMasterWorkSchedulingDatum

	dataPlatformProductMasterWorkSchedulingDatumQuery struct {
		*queries.Query
	}
)

// Cache for insert, update and upsert
var (
	dataPlatformProductMasterWorkSchedulingDatumType                 = reflect.TypeOf(&DataPlatformProductMasterWorkSchedulingDatum{})
	dataPlatformProductMasterWorkSchedulingDatumMapping              = queries.MakeStructMapping(dataPlatformProductMasterWorkSchedulingDatumType)
	dataPlatformProductMasterWorkSchedulingDatumPrimaryKeyMapping, _ = queries.BindMapping(dataPlatformProductMasterWorkSchedulingDatumType, dataPlatformProductMasterWorkSchedulingDatumMapping, dataPlatformProductMasterWorkSchedulingDatumPrimaryKeyColumns)
	dataPlatformProductMasterWorkSchedulingDatumInsertCacheMut       sync.RWMutex
	dataPlatformProductMasterWorkSchedulingDatumInsertCache          = make(map[string]insertCache)
	dataPlatformProductMasterWorkSchedulingDatumUpdateCacheMut       sync.RWMutex
	dataPlatformProductMasterWorkSchedulingDatumUpdateCache          = make(map[string]updateCache)
	dataPlatformProductMasterWorkSchedulingDatumUpsertCacheMut       sync.RWMutex
	dataPlatformProductMasterWorkSchedulingDatumUpsertCache          = make(map[string]insertCache)
)

var (
	// Force time package dependency for automated UpdatedAt/CreatedAt.
	_ = time.Second
	// Force qmhelper dependency for where clause generation (which doesn't
	// always happen)
	_ = qmhelper.Where
)

// One returns a single dataPlatformProductMasterWorkSchedulingDatum record from the query.
func (q dataPlatformProductMasterWorkSchedulingDatumQuery) One(ctx context.Context, exec boil.ContextExecutor) (*DataPlatformProductMasterWorkSchedulingDatum, error) {
	o := &DataPlatformProductMasterWorkSchedulingDatum{}

	queries.SetLimit(q.Query, 1)

	err := q.Bind(ctx, exec, o)
	if err != nil {
		if errors.Is(err, sql.ErrNoRows) {
			return nil, sql.ErrNoRows
		}
		return nil, errors.Wrap(err, "models: failed to execute a one query for data_platform_product_master_work_scheduling_data")
	}

	return o, nil
}

// All returns all DataPlatformProductMasterWorkSchedulingDatum records from the query.
func (q dataPlatformProductMasterWorkSchedulingDatumQuery) All(ctx context.Context, exec boil.ContextExecutor) (DataPlatformProductMasterWorkSchedulingDatumSlice, error) {
	var o []*DataPlatformProductMasterWorkSchedulingDatum

	err := q.Bind(ctx, exec, &o)
	if err != nil {
		return nil, errors.Wrap(err, "models: failed to assign all query results to DataPlatformProductMasterWorkSchedulingDatum slice")
	}

	return o, nil
}

// Count returns the count of all DataPlatformProductMasterWorkSchedulingDatum records in the query.
func (q dataPlatformProductMasterWorkSchedulingDatumQuery) Count(ctx context.Context, exec boil.ContextExecutor) (int64, error) {
	var count int64

	queries.SetSelect(q.Query, nil)
	queries.SetCount(q.Query)

	err := q.Query.QueryRowContext(ctx, exec).Scan(&count)
	if err != nil {
		return 0, errors.Wrap(err, "models: failed to count data_platform_product_master_work_scheduling_data rows")
	}

	return count, nil
}

// Exists checks if the row exists in the table.
func (q dataPlatformProductMasterWorkSchedulingDatumQuery) Exists(ctx context.Context, exec boil.ContextExecutor) (bool, error) {
	var count int64

	queries.SetSelect(q.Query, nil)
	queries.SetCount(q.Query)
	queries.SetLimit(q.Query, 1)

	err := q.Query.QueryRowContext(ctx, exec).Scan(&count)
	if err != nil {
		return false, errors.Wrap(err, "models: failed to check if data_platform_product_master_work_scheduling_data exists")
	}

	return count > 0, nil
}

// DataPlatformProductMasterWorkSchedulingData retrieves all the records using an executor.
func DataPlatformProductMasterWorkSchedulingData(mods ...qm.QueryMod) dataPlatformProductMasterWorkSchedulingDatumQuery {
	mods = append(mods, qm.From("`data_platform_product_master_work_scheduling_data`"))
	q := NewQuery(mods...)
	if len(queries.GetSelect(q)) == 0 {
		queries.SetSelect(q, []string{"`data_platform_product_master_work_scheduling_data`.*"})
	}

	return dataPlatformProductMasterWorkSchedulingDatumQuery{q}
}

// FindDataPlatformProductMasterWorkSchedulingDatum retrieves a single record by ID with an executor.
// If selectCols is empty Find will return all columns.
func FindDataPlatformProductMasterWorkSchedulingDatum(ctx context.Context, exec boil.ContextExecutor, product string, businessPartner int, plant string, selectCols ...string) (*DataPlatformProductMasterWorkSchedulingDatum, error) {
	dataPlatformProductMasterWorkSchedulingDatumObj := &DataPlatformProductMasterWorkSchedulingDatum{}

	sel := "*"
	if len(selectCols) > 0 {
		sel = strings.Join(strmangle.IdentQuoteSlice(dialect.LQ, dialect.RQ, selectCols), ",")
	}
	query := fmt.Sprintf(
		"select %s from `data_platform_product_master_work_scheduling_data` where `Product`=? AND `BusinessPartner`=? AND `Plant`=?", sel,
	)

	q := queries.Raw(query, product, businessPartner, plant)

	err := q.Bind(ctx, exec, dataPlatformProductMasterWorkSchedulingDatumObj)
	if err != nil {
		if errors.Is(err, sql.ErrNoRows) {
			return nil, sql.ErrNoRows
		}
		return nil, errors.Wrap(err, "models: unable to select from data_platform_product_master_work_scheduling_data")
	}

	return dataPlatformProductMasterWorkSchedulingDatumObj, nil
}

// Insert a single record using an executor.
// See boil.Columns.InsertColumnSet documentation to understand column list inference for inserts.
func (o *DataPlatformProductMasterWorkSchedulingDatum) Insert(ctx context.Context, exec boil.ContextExecutor, columns boil.Columns) error {
	if o == nil {
		return errors.New("models: no data_platform_product_master_work_scheduling_data provided for insertion")
	}

	var err error

	nzDefaults := queries.NonZeroDefaultSet(dataPlatformProductMasterWorkSchedulingDatumColumnsWithDefault, o)

	key := makeCacheKey(columns, nzDefaults)
	dataPlatformProductMasterWorkSchedulingDatumInsertCacheMut.RLock()
	cache, cached := dataPlatformProductMasterWorkSchedulingDatumInsertCache[key]
	dataPlatformProductMasterWorkSchedulingDatumInsertCacheMut.RUnlock()

	if !cached {
		wl, returnColumns := columns.InsertColumnSet(
			dataPlatformProductMasterWorkSchedulingDatumAllColumns,
			dataPlatformProductMasterWorkSchedulingDatumColumnsWithDefault,
			dataPlatformProductMasterWorkSchedulingDatumColumnsWithoutDefault,
			nzDefaults,
		)

		cache.valueMapping, err = queries.BindMapping(dataPlatformProductMasterWorkSchedulingDatumType, dataPlatformProductMasterWorkSchedulingDatumMapping, wl)
		if err != nil {
			return err
		}
		cache.retMapping, err = queries.BindMapping(dataPlatformProductMasterWorkSchedulingDatumType, dataPlatformProductMasterWorkSchedulingDatumMapping, returnColumns)
		if err != nil {
			return err
		}
		if len(wl) != 0 {
			cache.query = fmt.Sprintf("INSERT INTO `data_platform_product_master_work_scheduling_data` (`%s`) %%sVALUES (%s)%%s", strings.Join(wl, "`,`"), strmangle.Placeholders(dialect.UseIndexPlaceholders, len(wl), 1, 1))
		} else {
			cache.query = "INSERT INTO `data_platform_product_master_work_scheduling_data` () VALUES ()%s%s"
		}

		var queryOutput, queryReturning string

		if len(cache.retMapping) != 0 {
			cache.retQuery = fmt.Sprintf("SELECT `%s` FROM `data_platform_product_master_work_scheduling_data` WHERE %s", strings.Join(returnColumns, "`,`"), strmangle.WhereClause("`", "`", 0, dataPlatformProductMasterWorkSchedulingDatumPrimaryKeyColumns))
		}

		cache.query = fmt.Sprintf(cache.query, queryOutput, queryReturning)
	}

	value := reflect.Indirect(reflect.ValueOf(o))
	vals := queries.ValuesFromMapping(value, cache.valueMapping)

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, cache.query)
		fmt.Fprintln(writer, vals)
	}
	_, err = exec.ExecContext(ctx, cache.query, vals...)

	if err != nil {
		return errors.Wrap(err, "models: unable to insert into data_platform_product_master_work_scheduling_data")
	}

	var identifierCols []interface{}

	if len(cache.retMapping) == 0 {
		goto CacheNoHooks
	}

	identifierCols = []interface{}{
		o.Product,
		o.BusinessPartner,
		o.Plant,
	}

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, cache.retQuery)
		fmt.Fprintln(writer, identifierCols...)
	}
	err = exec.QueryRowContext(ctx, cache.retQuery, identifierCols...).Scan(queries.PtrsFromMapping(value, cache.retMapping)...)
	if err != nil {
		return errors.Wrap(err, "models: unable to populate default values for data_platform_product_master_work_scheduling_data")
	}

CacheNoHooks:
	if !cached {
		dataPlatformProductMasterWorkSchedulingDatumInsertCacheMut.Lock()
		dataPlatformProductMasterWorkSchedulingDatumInsertCache[key] = cache
		dataPlatformProductMasterWorkSchedulingDatumInsertCacheMut.Unlock()
	}

	return nil
}

// Update uses an executor to update the DataPlatformProductMasterWorkSchedulingDatum.
// See boil.Columns.UpdateColumnSet documentation to understand column list inference for updates.
// Update does not automatically update the record in case of default values. Use .Reload() to refresh the records.
func (o *DataPlatformProductMasterWorkSchedulingDatum) Update(ctx context.Context, exec boil.ContextExecutor, columns boil.Columns) error {
	var err error
	key := makeCacheKey(columns, nil)
	dataPlatformProductMasterWorkSchedulingDatumUpdateCacheMut.RLock()
	cache, cached := dataPlatformProductMasterWorkSchedulingDatumUpdateCache[key]
	dataPlatformProductMasterWorkSchedulingDatumUpdateCacheMut.RUnlock()

	if !cached {
		wl := columns.UpdateColumnSet(
			dataPlatformProductMasterWorkSchedulingDatumAllColumns,
			dataPlatformProductMasterWorkSchedulingDatumPrimaryKeyColumns,
		)

		if !columns.IsWhitelist() {
			wl = strmangle.SetComplement(wl, []string{"created_at"})
		}
		if len(wl) == 0 {
			return errors.New("models: unable to update data_platform_product_master_work_scheduling_data, could not build whitelist")
		}

		cache.query = fmt.Sprintf("UPDATE `data_platform_product_master_work_scheduling_data` SET %s WHERE %s",
			strmangle.SetParamNames("`", "`", 0, wl),
			strmangle.WhereClause("`", "`", 0, dataPlatformProductMasterWorkSchedulingDatumPrimaryKeyColumns),
		)
		cache.valueMapping, err = queries.BindMapping(dataPlatformProductMasterWorkSchedulingDatumType, dataPlatformProductMasterWorkSchedulingDatumMapping, append(wl, dataPlatformProductMasterWorkSchedulingDatumPrimaryKeyColumns...))
		if err != nil {
			return err
		}
	}

	values := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(o)), cache.valueMapping)

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, cache.query)
		fmt.Fprintln(writer, values)
	}
	_, err = exec.ExecContext(ctx, cache.query, values...)
	if err != nil {
		return errors.Wrap(err, "models: unable to update data_platform_product_master_work_scheduling_data row")
	}

	if !cached {
		dataPlatformProductMasterWorkSchedulingDatumUpdateCacheMut.Lock()
		dataPlatformProductMasterWorkSchedulingDatumUpdateCache[key] = cache
		dataPlatformProductMasterWorkSchedulingDatumUpdateCacheMut.Unlock()
	}

	return nil
}

// UpdateAll updates all rows with the specified column values.
func (q dataPlatformProductMasterWorkSchedulingDatumQuery) UpdateAll(ctx context.Context, exec boil.ContextExecutor, cols M) error {
	queries.SetUpdate(q.Query, cols)

	_, err := q.Query.ExecContext(ctx, exec)
	if err != nil {
		return errors.Wrap(err, "models: unable to update all for data_platform_product_master_work_scheduling_data")
	}

	return nil
}

// UpdateAll updates all rows with the specified column values, using an executor.
func (o DataPlatformProductMasterWorkSchedulingDatumSlice) UpdateAll(ctx context.Context, exec boil.ContextExecutor, cols M) error {
	ln := int64(len(o))
	if ln == 0 {
		return nil
	}

	if len(cols) == 0 {
		return errors.New("models: update all requires at least one column argument")
	}

	colNames := make([]string, len(cols))
	args := make([]interface{}, len(cols))

	i := 0
	for name, value := range cols {
		colNames[i] = name
		args[i] = value
		i++
	}

	// Append all of the primary key values for each column
	for _, obj := range o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), dataPlatformProductMasterWorkSchedulingDatumPrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := fmt.Sprintf("UPDATE `data_platform_product_master_work_scheduling_data` SET %s WHERE %s",
		strmangle.SetParamNames("`", "`", 0, colNames),
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), 0, dataPlatformProductMasterWorkSchedulingDatumPrimaryKeyColumns, len(o)))

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, sql)
		fmt.Fprintln(writer, args...)
	}
	_, err := exec.ExecContext(ctx, sql, args...)
	if err != nil {
		return errors.Wrap(err, "models: unable to update all in dataPlatformProductMasterWorkSchedulingDatum slice")
	}

	return nil
}

var mySQLDataPlatformProductMasterWorkSchedulingDatumUniqueColumns = []string{}

// Upsert attempts an insert using an executor, and does an update or ignore on conflict.
// See boil.Columns documentation for how to properly use updateColumns and insertColumns.
func (o *DataPlatformProductMasterWorkSchedulingDatum) Upsert(ctx context.Context, exec boil.ContextExecutor, updateColumns, insertColumns boil.Columns) error {
	if o == nil {
		return errors.New("models: no data_platform_product_master_work_scheduling_data provided for upsert")
	}

	nzDefaults := queries.NonZeroDefaultSet(dataPlatformProductMasterWorkSchedulingDatumColumnsWithDefault, o)
	nzUniques := queries.NonZeroDefaultSet(mySQLDataPlatformProductMasterWorkSchedulingDatumUniqueColumns, o)

	if len(nzUniques) == 0 {
		return errors.New("cannot upsert with a table that cannot conflict on a unique column")
	}

	// Build cache key in-line uglily - mysql vs psql problems
	buf := strmangle.GetBuffer()
	buf.WriteString(strconv.Itoa(updateColumns.Kind))
	for _, c := range updateColumns.Cols {
		buf.WriteString(c)
	}
	buf.WriteByte('.')
	buf.WriteString(strconv.Itoa(insertColumns.Kind))
	for _, c := range insertColumns.Cols {
		buf.WriteString(c)
	}
	buf.WriteByte('.')
	for _, c := range nzDefaults {
		buf.WriteString(c)
	}
	buf.WriteByte('.')
	for _, c := range nzUniques {
		buf.WriteString(c)
	}
	key := buf.String()
	strmangle.PutBuffer(buf)

	dataPlatformProductMasterWorkSchedulingDatumUpsertCacheMut.RLock()
	cache, cached := dataPlatformProductMasterWorkSchedulingDatumUpsertCache[key]
	dataPlatformProductMasterWorkSchedulingDatumUpsertCacheMut.RUnlock()

	var err error

	if !cached {
		insert, ret := insertColumns.InsertColumnSet(
			dataPlatformProductMasterWorkSchedulingDatumAllColumns,
			dataPlatformProductMasterWorkSchedulingDatumColumnsWithDefault,
			dataPlatformProductMasterWorkSchedulingDatumColumnsWithoutDefault,
			nzDefaults,
		)

		update := updateColumns.UpdateColumnSet(
			dataPlatformProductMasterWorkSchedulingDatumAllColumns,
			dataPlatformProductMasterWorkSchedulingDatumPrimaryKeyColumns,
		)

		if !updateColumns.IsNone() && len(update) == 0 {
			return errors.New("models: unable to upsert data_platform_product_master_work_scheduling_data, could not build update column list")
		}

		ret = strmangle.SetComplement(ret, nzUniques)
		cache.query = buildUpsertQueryMySQL(dialect, "`data_platform_product_master_work_scheduling_data`", update, insert)
		cache.retQuery = fmt.Sprintf(
			"SELECT %s FROM `data_platform_product_master_work_scheduling_data` WHERE %s",
			strings.Join(strmangle.IdentQuoteSlice(dialect.LQ, dialect.RQ, ret), ","),
			strmangle.WhereClause("`", "`", 0, nzUniques),
		)

		cache.valueMapping, err = queries.BindMapping(dataPlatformProductMasterWorkSchedulingDatumType, dataPlatformProductMasterWorkSchedulingDatumMapping, insert)
		if err != nil {
			return err
		}
		if len(ret) != 0 {
			cache.retMapping, err = queries.BindMapping(dataPlatformProductMasterWorkSchedulingDatumType, dataPlatformProductMasterWorkSchedulingDatumMapping, ret)
			if err != nil {
				return err
			}
		}
	}

	value := reflect.Indirect(reflect.ValueOf(o))
	vals := queries.ValuesFromMapping(value, cache.valueMapping)
	var returns []interface{}
	if len(cache.retMapping) != 0 {
		returns = queries.PtrsFromMapping(value, cache.retMapping)
	}

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, cache.query)
		fmt.Fprintln(writer, vals)
	}
	_, err = exec.ExecContext(ctx, cache.query, vals...)

	if err != nil {
		return errors.Wrap(err, "models: unable to upsert for data_platform_product_master_work_scheduling_data")
	}

	var uniqueMap []uint64
	var nzUniqueCols []interface{}

	if len(cache.retMapping) == 0 {
		goto CacheNoHooks
	}

	uniqueMap, err = queries.BindMapping(dataPlatformProductMasterWorkSchedulingDatumType, dataPlatformProductMasterWorkSchedulingDatumMapping, nzUniques)
	if err != nil {
		return errors.Wrap(err, "models: unable to retrieve unique values for data_platform_product_master_work_scheduling_data")
	}
	nzUniqueCols = queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(o)), uniqueMap)

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, cache.retQuery)
		fmt.Fprintln(writer, nzUniqueCols...)
	}
	err = exec.QueryRowContext(ctx, cache.retQuery, nzUniqueCols...).Scan(returns...)
	if err != nil {
		return errors.Wrap(err, "models: unable to populate default values for data_platform_product_master_work_scheduling_data")
	}

CacheNoHooks:
	if !cached {
		dataPlatformProductMasterWorkSchedulingDatumUpsertCacheMut.Lock()
		dataPlatformProductMasterWorkSchedulingDatumUpsertCache[key] = cache
		dataPlatformProductMasterWorkSchedulingDatumUpsertCacheMut.Unlock()
	}

	return nil
}

// Delete deletes a single DataPlatformProductMasterWorkSchedulingDatum record with an executor.
// Delete will match against the primary key column to find the record to delete.
func (o *DataPlatformProductMasterWorkSchedulingDatum) Delete(ctx context.Context, exec boil.ContextExecutor) error {
	if o == nil {
		return errors.New("models: no DataPlatformProductMasterWorkSchedulingDatum provided for delete")
	}

	args := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(o)), dataPlatformProductMasterWorkSchedulingDatumPrimaryKeyMapping)
	sql := "DELETE FROM `data_platform_product_master_work_scheduling_data` WHERE `Product`=? AND `BusinessPartner`=? AND `Plant`=?"

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, sql)
		fmt.Fprintln(writer, args...)
	}
	_, err := exec.ExecContext(ctx, sql, args...)
	if err != nil {
		return errors.Wrap(err, "models: unable to delete from data_platform_product_master_work_scheduling_data")
	}

	return nil
}

// DeleteAll deletes all matching rows.
func (q dataPlatformProductMasterWorkSchedulingDatumQuery) DeleteAll(ctx context.Context, exec boil.ContextExecutor) error {
	if q.Query == nil {
		return errors.New("models: no dataPlatformProductMasterWorkSchedulingDatumQuery provided for delete all")
	}

	queries.SetDelete(q.Query)

	_, err := q.Query.ExecContext(ctx, exec)
	if err != nil {
		return errors.Wrap(err, "models: unable to delete all from data_platform_product_master_work_scheduling_data")
	}

	return nil
}

// DeleteAll deletes all rows in the slice, using an executor.
func (o DataPlatformProductMasterWorkSchedulingDatumSlice) DeleteAll(ctx context.Context, exec boil.ContextExecutor) error {
	if len(o) == 0 {
		return nil
	}

	var args []interface{}
	for _, obj := range o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), dataPlatformProductMasterWorkSchedulingDatumPrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := "DELETE FROM `data_platform_product_master_work_scheduling_data` WHERE " +
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), 0, dataPlatformProductMasterWorkSchedulingDatumPrimaryKeyColumns, len(o))

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, sql)
		fmt.Fprintln(writer, args)
	}
	_, err := exec.ExecContext(ctx, sql, args...)
	if err != nil {
		return errors.Wrap(err, "models: unable to delete all from dataPlatformProductMasterWorkSchedulingDatum slice")
	}

	return nil
}

// Reload refetches the object from the database
// using the primary keys with an executor.
func (o *DataPlatformProductMasterWorkSchedulingDatum) Reload(ctx context.Context, exec boil.ContextExecutor) error {
	ret, err := FindDataPlatformProductMasterWorkSchedulingDatum(ctx, exec, o.Product, o.BusinessPartner, o.Plant)
	if err != nil {
		return err
	}

	*o = *ret
	return nil
}

// ReloadAll refetches every row with matching primary key column values
// and overwrites the original object slice with the newly updated slice.
func (o *DataPlatformProductMasterWorkSchedulingDatumSlice) ReloadAll(ctx context.Context, exec boil.ContextExecutor) error {
	if o == nil || len(*o) == 0 {
		return nil
	}

	slice := DataPlatformProductMasterWorkSchedulingDatumSlice{}
	var args []interface{}
	for _, obj := range *o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), dataPlatformProductMasterWorkSchedulingDatumPrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := "SELECT `data_platform_product_master_work_scheduling_data`.* FROM `data_platform_product_master_work_scheduling_data` WHERE " +
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), 0, dataPlatformProductMasterWorkSchedulingDatumPrimaryKeyColumns, len(*o))

	q := queries.Raw(sql, args...)

	err := q.Bind(ctx, exec, &slice)
	if err != nil {
		return errors.Wrap(err, "models: unable to reload all in DataPlatformProductMasterWorkSchedulingDatumSlice")
	}

	*o = slice

	return nil
}

// DataPlatformProductMasterWorkSchedulingDatumExists checks if the DataPlatformProductMasterWorkSchedulingDatum row exists.
func DataPlatformProductMasterWorkSchedulingDatumExists(ctx context.Context, exec boil.ContextExecutor, product string, businessPartner int, plant string) (bool, error) {
	var exists bool
	sql := "select exists(select 1 from `data_platform_product_master_work_scheduling_data` where `Product`=? AND `BusinessPartner`=? AND `Plant`=? limit 1)"

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, sql)
		fmt.Fprintln(writer, product, businessPartner, plant)
	}
	row := exec.QueryRowContext(ctx, sql, product, businessPartner, plant)

	err := row.Scan(&exists)
	if err != nil {
		return false, errors.Wrap(err, "models: unable to check if data_platform_product_master_work_scheduling_data exists")
	}

	return exists, nil
}

// Exists checks if the DataPlatformProductMasterWorkSchedulingDatum row exists.
func (o *DataPlatformProductMasterWorkSchedulingDatum) Exists(ctx context.Context, exec boil.ContextExecutor) (bool, error) {
	return DataPlatformProductMasterWorkSchedulingDatumExists(ctx, exec, o.Product, o.BusinessPartner, o.Plant)
}
